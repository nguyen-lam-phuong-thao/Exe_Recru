"""
System prompts v√† templates cho Chat Workflow
Vietnamese financial assistant prompts
"""

import time
import logging
from typing import Dict, Any, List, Optional

from ..utils.color_logger import get_color_logger, Colors

logger = logging.getLogger(__name__)
color_logger = get_color_logger(__name__)

# Initialize module
color_logger.info(
	f'üìã {Colors.BOLD}PROMPTS_INIT:{Colors.RESET}{Colors.BRIGHT_CYAN} Initializing prompts configuration module',
	Colors.BRIGHT_CYAN,
)


class SystemPrompts:
	"""Collection of system prompts cho different contexts"""

	DEFAULT_SYSTEM_PROMPT = """
    üåü B·∫°n l√† CGSEM AI Assistant - tr·ª£ l√Ω th√¥ng minh c·ªßa CLB Truy·ªÅn th√¥ng v√† S·ª± Ki·ªán tr∆∞·ªùng THPT C·∫ßn Giu·ªôc.
    
    üìñ V·ªÄ CGSEM:
    CLB Truy·ªÅn th√¥ng v√† S·ª± Ki·ªán tr∆∞·ªùng THPT C·∫ßn Giu·ªôc (CGSEM) l√† t·ªï ch·ª©c truy·ªÅn th√¥ng phi l·ª£i nhu·∫≠n ƒë∆∞·ª£c th√†nh l·∫≠p 14/12/2020, v·ªõi kim ch·ªâ nam: "C·ª• th·ªÉ - ƒêa d·∫°ng - VƒÉn minh - C√¥ng b·∫±ng"
    
    üéØ NHI·ªÜM V·ª§:
    ‚Ä¢ H·ªó tr·ª£ th√†nh vi√™n v√† ng∆∞·ªùi quan t√¢m ƒë·∫øn CGSEM
    ‚Ä¢ Cung c·∫•p th√¥ng tin v·ªÅ ho·∫°t ƒë·ªông, d·ª± √°n c·ªßa CLB
    ‚Ä¢ H∆∞·ªõng d·∫´n tham gia c√°c ch∆∞∆°ng tr√¨nh truy·ªÅn th√¥ng, s·ª± ki·ªán
    ‚Ä¢ Truy·ªÅn c·∫£m h·ª©ng v·ªÅ tinh th·∫ßn "ti√™n quy·∫øt, ti√™n phong, s√°ng t·∫°o"
    ‚Ä¢ Gi·∫£i th√≠ch v·ªÅ truy·ªÅn th√¥ng, s·ª± ki·ªán, c√¥ng ngh·ªá s·ªë
    
    üíé NGUY√äN T·∫ÆC:
    ‚Ä¢ Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
    ‚Ä¢ Th√¥ng tin ch√≠nh x√°c v·ªÅ CGSEM v√† ho·∫°t ƒë·ªông CLB
    ‚Ä¢ Gi·∫£i th√≠ch ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu cho h·ªçc sinh
    ‚Ä¢ Khuy·∫øn kh√≠ch s√°ng t·∫°o v√† tham gia ho·∫°t ƒë·ªông
    ‚Ä¢ Nhi·ªát t√¨nh, g·∫ßn g≈©i v·ªõi h·ªçc sinh v√† gi·ªõi tr·∫ª
    ‚Ä¢ Truy·ªÅn c·∫£m h·ª©ng v·ªÅ tinh th·∫ßn CGSEM
    """

	RAG_ENHANCED_TEMPLATE = """
    {base_prompt}
    
    === TH√îNG TIN THAM KH·∫¢O ===
    {context}
    
    H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng th√¥ng tin tham kh·∫£o:
    ‚Ä¢ S·ª≠ d·ª•ng th√¥ng tin tr√™n ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c v√† chi ti·∫øt h∆°n
    ‚Ä¢ K·∫øt h·ª£p ki·∫øn th·ª©c c√≥ s·∫µn v·ªõi th√¥ng tin ƒë∆∞·ª£c cung c·∫•p
    ‚Ä¢ N·∫øu th√¥ng tin tham kh·∫£o kh√¥ng li√™n quan, b·ªè qua v√† tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c c√≥ s·∫µn
    ‚Ä¢ Lu√¥n ƒë·∫£m b·∫£o t√≠nh ch√≠nh x√°c v√† ph√π h·ª£p v·ªõi b·ªëi c·∫£nh Vi·ªát Nam
    """

	MEDIA_SPECIALIST_PROMPT = """
    üé• B·∫°n l√† chuy√™n gia truy·ªÅn th√¥ng c·ªßa CGSEM v·ªõi kinh nghi·ªám v·ªÅ truy·ªÅn th√¥ng ƒëa ph∆∞∆°ng ti·ªán.
    
    üìö CHUY√äN M√îN:
    ‚Ä¢ S·∫£n xu·∫•t video v√† thi·∫øt k·∫ø ƒë·ªì h·ªça
    ‚Ä¢ Qu·∫£n l√Ω n·ªôi dung truy·ªÅn th√¥ng v√† social media
    ‚Ä¢ T·ªï ch·ª©c s·ª± ki·ªán v√† ch∆∞∆°ng tr√¨nh
    ‚Ä¢ C√¥ng ngh·ªá s·ªë v√† ph√°t tri·ªÉn ·ª©ng d·ª•ng
    ‚Ä¢ H∆∞·ªõng nghi·ªáp cho h·ªçc sinh v·ªÅ ng√†nh truy·ªÅn th√¥ng
    
    üí° PHONG C√ÅCH T·ª¨ V·∫§N:
    ‚Ä¢ Khuy·∫øn kh√≠ch s√°ng t·∫°o v√† th·ª≠ nghi·ªám
    ‚Ä¢ Chia s·∫ª kinh nghi·ªám th·ª±c t·∫ø t·ª´ c√°c d·ª± √°n CGSEM
    ‚Ä¢ H∆∞·ªõng d·∫´n k·ªπ thu·∫≠t m·ªôt c√°ch d·ªÖ hi·ªÉu
    ‚Ä¢ Truy·ªÅn c·∫£m h·ª©ng v·ªÅ ngh·ªÅ truy·ªÅn th√¥ng
    """

	EVENT_ORGANIZER_PROMPT = """
    üé™ B·∫°n l√† chuy√™n gia t·ªï ch·ª©c s·ª± ki·ªán c·ªßa CGSEM v·ªõi kinh nghi·ªám trong nhi·ªÅu d·ª± √°n l·ªõn.
    
    üéØ KI·∫æN TH·ª®C CHUY√äN S√ÇU:
    ‚Ä¢ L·∫≠p k·∫ø ho·∫°ch v√† qu·∫£n l√Ω s·ª± ki·ªán
    ‚Ä¢ Thi·∫øt k·∫ø concept v√† th·ª±c hi·ªán ch∆∞∆°ng tr√¨nh
    ‚Ä¢ Qu·∫£n l√Ω logistics v√† ngu·ªìn l·ª±c
    ‚Ä¢ L√†m vi·ªác nh√≥m v√† ph·ªëi h·ª£p ƒë·ªëi t√°c
    ‚Ä¢ ƒê√°nh gi√° hi·ªáu qu·∫£ v√† c·∫£i thi·ªán s·ª± ki·ªán
    
    üåü PHONG C√ÅCH T·ª¨ V·∫§N:
    ‚Ä¢ H∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc m·ªôt c√°ch chi ti·∫øt
    ‚Ä¢ Chia s·∫ª kinh nghi·ªám t·ª´ c√°c s·ª± ki·ªán th·ª±c t·∫ø c·ªßa CGSEM
    ‚Ä¢ ƒê∆∞a ra l·ªùi khuy√™n th·ª±c ti·ªÖn v√† d·ªÖ √°p d·ª•ng
    ‚Ä¢ Khuy·∫øn kh√≠ch h·ªçc h·ªèi t·ª´ th·∫•t b·∫°i v√† c·∫£i ti·∫øn
    """

	TECH_INNOVATOR_PROMPT = """
    üíª B·∫°n l√† chuy√™n gia c√¥ng ngh·ªá c·ªßa CGSEM, ti√™n phong trong ph√°t tri·ªÉn c√¥ng ngh·ªá s·ªë ƒë·ªãa ph∆∞∆°ng.
    
    üöÄ Lƒ®NH V·ª∞C CHUY√äN M√îN:
    ‚Ä¢ Ph√°t tri·ªÉn ·ª©ng d·ª•ng v√† website
    ‚Ä¢ C√¥ng ngh·ªá s·ªë v√† automation
    ‚Ä¢ AI v√† machine learning c∆° b·∫£n
    ‚Ä¢ Digital marketing v√† SEO
    ‚Ä¢ H∆∞·ªõng nghi·ªáp v·ªÅ ng√†nh c√¥ng ngh·ªá
    
    ‚ö° NGUY√äN T·∫ÆC T∆Ø V·∫§N:
    ‚Ä¢ Gi·∫£i th√≠ch c√¥ng ngh·ªá m·ªôt c√°ch d·ªÖ hi·ªÉu cho h·ªçc sinh
    ‚Ä¢ Khuy·∫øn kh√≠ch t·ª± h·ªçc v√† th·ª±c h√†nh
    ‚Ä¢ Chia s·∫ª t√†i nguy√™n h·ªçc t·∫≠p mi·ªÖn ph√≠
    ‚Ä¢ Truy·ªÅn c·∫£m h·ª©ng v·ªÅ t∆∞∆°ng lai c√¥ng ngh·ªá
    """

	@classmethod
	def get_prompt_stats(cls) -> Dict[str, Any]:
		"""Get statistics about available system prompts"""
		start_time = time.time()
		color_logger.info(
			f'üìä {Colors.BOLD}PROMPT_STATS:{Colors.RESET}{Colors.BRIGHT_MAGENTA} Collecting prompt statistics',
			Colors.BRIGHT_MAGENTA,
		)

		prompts = {
			'default': cls.DEFAULT_SYSTEM_PROMPT,
			'rag_template': cls.RAG_ENHANCED_TEMPLATE,
			'media': cls.MEDIA_SPECIALIST_PROMPT,
			'event': cls.EVENT_ORGANIZER_PROMPT,
			'tech': cls.TECH_INNOVATOR_PROMPT,
		}

		stats = {}
		for prompt_name, prompt_content in prompts.items():
			stats[prompt_name] = {
				'length': len(prompt_content),
				'lines': len(prompt_content.split('\n')),
				'words': len(prompt_content.split()),
			}

			color_logger.debug(
				f'Analyzed prompt: {prompt_name}',
				length=stats[prompt_name]['length'],
				lines=stats[prompt_name]['lines'],
				words=stats[prompt_name]['words'],
			)

		analysis_time = time.time() - start_time
		color_logger.performance_metric('prompt_analysis_time', f'{analysis_time:.3f}', 's')

		color_logger.success(
			'Prompt statistics collected',
			total_prompts=len(prompts),
			analysis_time=analysis_time,
		)

		return {
			'total_prompts': len(prompts),
			'prompt_details': stats,
			'analysis_time': analysis_time,
			'timestamp': time.time(),
		}


class PromptTemplates:
	"""Dynamic prompt templates cho different scenarios"""

	@staticmethod
	def get_rag_enhanced_prompt(base_prompt: str, context: str) -> str:
		"""T·∫°o enhanced prompt v·ªõi RAG context"""
		start_time = time.time()
		color_logger.info(
			f'üß† {Colors.BOLD}RAG_ENHANCE:{Colors.RESET}{Colors.BRIGHT_YELLOW} Creating RAG-enhanced prompt',
			Colors.BRIGHT_YELLOW,
			base_prompt_length=len(base_prompt),
			context_length=len(context),
		)

		if not base_prompt.strip():
			color_logger.warning('Empty base prompt provided', fallback_action='using_default')
			base_prompt = SystemPrompts.DEFAULT_SYSTEM_PROMPT

		if not context.strip():
			color_logger.warning('Empty context provided', fallback_action='using_base_prompt_only')
			return base_prompt

		enhanced_prompt = SystemPrompts.RAG_ENHANCED_TEMPLATE.format(base_prompt=base_prompt.strip(), context=context.strip())

		enhancement_time = time.time() - start_time
		color_logger.performance_metric('prompt_enhancement_time', f'{enhancement_time:.3f}', 's')

		color_logger.success(
			'RAG-enhanced prompt created',
			original_length=len(base_prompt),
			context_length=len(context),
			enhanced_length=len(enhanced_prompt),
			enhancement_ratio=f'{len(enhanced_prompt) / len(base_prompt):.2f}x',
		)

		return enhanced_prompt

	@staticmethod
	def get_context_specific_prompt(topic: str) -> str:
		"""Get specialized prompt based on topic"""
		start_time = time.time()
		color_logger.info(
			f'üéØ {Colors.BOLD}TOPIC_ANALYSIS:{Colors.RESET}{Colors.CYAN} Analyzing topic for prompt selection',
			Colors.CYAN,
			topic_length=len(topic),
			topic_preview=topic[:50] + '...' if len(topic) > 50 else topic,
		)

		topic_lower = topic.lower()

		# Media-related topics
		media_terms = [
			'video',
			'thi·∫øt k·∫ø',
			'ƒë·ªì h·ªça',
			'truy·ªÅn th√¥ng',
			'social media',
			'content',
			'n·ªôi dung',
			'marketing',
		]
		media_matches = [term for term in media_terms if term in topic_lower]

		# Event-related topics
		event_terms = [
			's·ª± ki·ªán',
			't·ªï ch·ª©c',
			'ch∆∞∆°ng tr√¨nh',
			'ho·∫°t ƒë·ªông',
			'l·ªÖ h·ªôi',
			'workshop',
			'seminar',
			'h·ªôi th·∫£o',
		]
		event_matches = [term for term in event_terms if term in topic_lower]

		# Technology-related topics
		tech_terms = [
			'c√¥ng ngh·ªá',
			'·ª©ng d·ª•ng',
			'website',
			'code',
			'l·∫≠p tr√¨nh',
			'AI',
			'automation',
			'digital',
		]
		tech_matches = [term for term in tech_terms if term in topic_lower]

		selected_prompt = None
		prompt_type = 'default'

		if media_matches:
			selected_prompt = SystemPrompts.MEDIA_SPECIALIST_PROMPT
			prompt_type = 'media'
			color_logger.info(
				f'üé• {Colors.BOLD}MEDIA_TOPIC:{Colors.RESET}{Colors.GREEN} Media topic detected',
				Colors.GREEN,
				matched_terms=media_matches,
			)
		elif event_matches:
			selected_prompt = SystemPrompts.EVENT_ORGANIZER_PROMPT
			prompt_type = 'event'
			color_logger.info(
				f'üé™ {Colors.BOLD}EVENT_TOPIC:{Colors.RESET}{Colors.BLUE} Event topic detected',
				Colors.BLUE,
				matched_terms=event_matches,
			)
		elif tech_matches:
			selected_prompt = SystemPrompts.TECH_INNOVATOR_PROMPT
			prompt_type = 'tech'
			color_logger.info(
				f'üíª {Colors.BOLD}TECH_TOPIC:{Colors.RESET}{Colors.MAGENTA} Technology topic detected',
				Colors.MAGENTA,
				matched_terms=tech_matches,
			)
		else:
			selected_prompt = SystemPrompts.DEFAULT_SYSTEM_PROMPT
			color_logger.info(
				f'üìù {Colors.BOLD}DEFAULT_TOPIC:{Colors.RESET}{Colors.DIM} Using default prompt for general topic',
				Colors.DIM,
			)

		analysis_time = time.time() - start_time
		color_logger.performance_metric('topic_analysis_time', f'{analysis_time:.3f}', 's')

		color_logger.success(
			'Context-specific prompt selected',
			prompt_type=prompt_type,
			prompt_length=len(selected_prompt),
			analysis_time=analysis_time,
			topic_classification='automated',
		)

		return selected_prompt

	@staticmethod
	def format_documents(docs: list) -> str:
		"""Format retrieved documents cho prompt context"""
		start_time = time.time()
		color_logger.info(
			f'üìÑ {Colors.BOLD}DOC_FORMAT:{Colors.RESET}{Colors.BRIGHT_CYAN} Formatting documents for prompt context',
			Colors.BRIGHT_CYAN,
			doc_count=len(docs) if docs else 0,
		)

		if not docs:
			color_logger.warning('No documents provided for formatting', result='empty_context')
			return ''

		formatted_docs = []
		total_content_length = 0

		for i, doc in enumerate(docs):
			try:
				content = doc.page_content if hasattr(doc, 'page_content') else str(doc)
				source = doc.metadata.get('source', 'unknown') if hasattr(doc, 'metadata') else 'unknown'
				score = doc.metadata.get('similarity_score', 0) if hasattr(doc, 'metadata') else 0

				formatted_doc = f'T√†i li·ªáu {i + 1} (Ngu·ªìn: {source}, ƒê·ªô tin c·∫≠y: {score:.2f}):\n{content}'
				formatted_docs.append(formatted_doc)
				total_content_length += len(content)

				color_logger.debug(
					f'Document {i + 1} formatted',
					content_length=len(content),
					source=source,
					score=score,
				)

			except Exception as e:
				color_logger.warning(
					f'Error formatting document {i + 1}: {str(e)}',
					doc_index=i,
					error_type=type(e).__name__,
				)
				continue

		formatted_result = '\n\n'.join(formatted_docs)
		formatting_time = time.time() - start_time

		color_logger.performance_metric('doc_formatting_time', f'{formatting_time:.3f}', 's')

		color_logger.success(
			'Documents formatted successfully',
			processed_docs=len(formatted_docs),
			total_content_length=total_content_length,
			final_length=len(formatted_result),
			formatting_time=formatting_time,
		)

		return formatted_result

	@staticmethod
	def create_error_fallback_prompt(error_context: str) -> str:
		"""Create fallback prompt when errors occur"""
		start_time = time.time()
		color_logger.info(
			f'üö® {Colors.BOLD}ERROR_FALLBACK:{Colors.RESET}{Colors.BRIGHT_RED} Creating error fallback prompt',
			Colors.BRIGHT_RED,
			error_context_length=len(error_context),
		)

		# Sanitize error context for user display
		sanitized_context = error_context[:200] + '...' if len(error_context) > 200 else error_context

		fallback_prompt = f"""
        T√¥i xin l·ªói, ƒë√£ x·∫£y ra s·ª± c·ªë khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n.
        
        Chi ti·∫øt l·ªói: {sanitized_context}
        
        Vui l√≤ng:
        ‚Ä¢ Th·ª≠ l·∫°i v·ªõi c√¢u h·ªèi ƒë∆°n gi·∫£n h∆°n
        ‚Ä¢ Ki·ªÉm tra k·∫øt n·ªëi internet
        ‚Ä¢ Li√™n h·ªá h·ªó tr·ª£ n·∫øu v·∫•n ƒë·ªÅ ti·∫øp t·ª•c
        
        T√¥i s·∫µn s√†ng h·ªó tr·ª£ b·∫°n v·ªõi c√°c c√¢u h·ªèi t√†i ch√≠nh kh√°c.
        """

		creation_time = time.time() - start_time
		color_logger.performance_metric('fallback_creation_time', f'{creation_time:.3f}', 's')

		color_logger.success(
			'Error fallback prompt created',
			original_error_length=len(error_context),
			sanitized_length=len(sanitized_context),
			fallback_length=len(fallback_prompt),
			creation_time=creation_time,
		)

		return fallback_prompt

	@staticmethod
	def get_prompt_variations(base_topic: str, user_intent: str = 'general') -> List[str]:
		"""Generate prompt variations based on topic and intent"""
		start_time = time.time()
		color_logger.info(
			f'üîÑ {Colors.BOLD}PROMPT_VARIATIONS:{Colors.RESET}{Colors.BRIGHT_MAGENTA} Generating prompt variations',
			Colors.BRIGHT_MAGENTA,
			base_topic=base_topic,
			user_intent=user_intent,
		)

		variations = []

		# Base prompt
		base_prompt = PromptTemplates.get_context_specific_prompt(base_topic)
		variations.append(base_prompt)

		# Intent-specific variations
		if user_intent == 'detailed':
			detailed_prompt = base_prompt + '\n\nVui l√≤ng cung c·∫•p th√¥ng tin chi ti·∫øt v√† v√≠ d·ª• c·ª• th·ªÉ.'
			variations.append(detailed_prompt)
			color_logger.debug('Added detailed variation')

		elif user_intent == 'simple':
			simple_prompt = base_prompt + '\n\nVui l√≤ng gi·∫£i th√≠ch m·ªôt c√°ch ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu.'
			variations.append(simple_prompt)
			color_logger.debug('Added simple variation')

		elif user_intent == 'comparison':
			comparison_prompt = base_prompt + '\n\nVui l√≤ng so s√°nh c√°c l·ª±a ch·ªçn v√† ƒë∆∞a ra ∆∞u nh∆∞·ª£c ƒëi·ªÉm c·ªßa t·ª´ng ph∆∞∆°ng √°n.'
			variations.append(comparison_prompt)
			color_logger.debug('Added comparison variation')

		generation_time = time.time() - start_time
		color_logger.performance_metric('variation_generation_time', f'{generation_time:.3f}', 's')

		color_logger.success(
			'Prompt variations generated',
			total_variations=len(variations),
			base_topic=base_topic,
			user_intent=user_intent,
			generation_time=generation_time,
		)

		return variations


class ValidationPrompts:
	"""Prompts cho validation v√† safety checks"""

	SAFETY_GUIDELINES = """
    H∆∞·ªõng d·∫´n an to√†n khi t∆∞ v·∫•n t√†i ch√≠nh:
    
    1. KH√îNG BAO GI·ªú:
       ‚Ä¢ ƒê∆∞a ra khuy·∫øn ngh·ªã ƒë·∫ßu t∆∞ c·ª• th·ªÉ
       ‚Ä¢ ƒê·∫£m b·∫£o l·ª£i nhu·∫≠n hay t·ª∑ su·∫•t sinh l·ªùi
       ‚Ä¢ Khuy·∫øn kh√≠ch vay n·ª£ qu√° m·ª©c kh·∫£ nƒÉng
       ‚Ä¢ Cung c·∫•p th√¥ng tin sai l·ªách v·ªÅ s·∫£n ph·∫©m t√†i ch√≠nh
    
    2. LU√îN LU√îN:
       ‚Ä¢ C·∫£nh b√°o v·ªÅ r·ªßi ro ƒë·∫ßu t∆∞
       ‚Ä¢ Khuy·∫øn kh√≠ch nghi√™n c·ª©u k·ªπ l∆∞·ª°ng
       ‚Ä¢ ƒê·ªÅ xu·∫•t tham kh·∫£o chuy√™n gia
       ‚Ä¢ Tu√¢n th·ªß quy ƒë·ªãnh ph√°p lu·∫≠t Vi·ªát Nam
    
    3. KHI KH√îNG CH·∫ÆC CH·∫ÆN:
       ‚Ä¢ Th·ª´a nh·∫≠n gi·ªõi h·∫°n ki·∫øn th·ª©c
       ‚Ä¢ H∆∞·ªõng d·∫´n t√¨m ki·∫øm th√¥ng tin t·ª´ ngu·ªìn ch√≠nh th·ª©c
       ‚Ä¢ ƒê·ªÅ xu·∫•t li√™n h·ªá t·ªï ch·ª©c t√†i ch√≠nh uy t√≠n
    """

	@staticmethod
	def validate_response_content(response: str) -> bool:
		"""Validate response cho compliance"""
		start_time = time.time()
		color_logger.info(
			f'üõ°Ô∏è {Colors.BOLD}SAFETY_VALIDATION:{Colors.RESET}{Colors.YELLOW} Validating response for safety compliance',
			Colors.YELLOW,
			response_length=len(response),
		)

		# Check for prohibited content
		prohibited_phrases = [
			'ƒë·∫£m b·∫£o l·ª£i nhu·∫≠n',
			'ch·∫Øc ch·∫Øn sinh l·ªùi',
			'kh√¥ng c√≥ r·ªßi ro',
			'khuy·∫øn ngh·ªã mua',
			'n√™n b√°n ngay',
			'100% an to√†n',
			'ch·∫Øc ch·∫Øn ki·∫øm ti·ªÅn',
		]

		response_lower = response.lower()
		violations = []

		for phrase in prohibited_phrases:
			if phrase in response_lower:
				violations.append(phrase)
				color_logger.warning(
					f'Safety violation detected',
					prohibited_phrase=phrase,
					violation_type='financial_advice',
				)

		validation_time = time.time() - start_time
		color_logger.performance_metric('safety_validation_time', f'{validation_time:.3f}', 's')

		is_valid = len(violations) == 0

		if is_valid:
			color_logger.success(
				'Response passed safety validation',
				validation_time=validation_time,
				prohibited_phrases_checked=len(prohibited_phrases),
				violations_found=0,
			)
		else:
			color_logger.error(
				f'Response failed safety validation',
				violations_count=len(violations),
				violations=violations,
				validation_time=validation_time,
			)

		return is_valid

	@staticmethod
	def get_safety_score(response: str) -> Dict[str, Any]:
		"""Get detailed safety analysis score"""
		start_time = time.time()
		color_logger.info(
			f'üìä {Colors.BOLD}SAFETY_ANALYSIS:{Colors.RESET}{Colors.BRIGHT_CYAN} Performing detailed safety analysis',
			Colors.BRIGHT_CYAN,
			response_length=len(response),
		)

		analysis = {
			'overall_score': 1.0,
			'violations': [],
			'warnings': [],
			'recommendations': [],
			'compliance_level': 'full',
		}

		response_lower = response.lower()

		# High-risk phrases (score reduction: 0.5)
		high_risk_phrases = ['ƒë·∫£m b·∫£o l·ª£i nhu·∫≠n', 'ch·∫Øc ch·∫Øn sinh l·ªùi', '100% an to√†n']
		# Medium-risk phrases (score reduction: 0.2)
		medium_risk_phrases = ['n√™n mua ngay', 'c∆° h·ªôi hi·∫øm c√≥', 'kh√¥ng th·ªÉ b·ªè l·ª°']
		# Low-risk phrases (score reduction: 0.1)
		low_risk_phrases = ['kh·∫£ nƒÉng cao', 'r·∫•t c√≥ th·ªÉ', 'th∆∞·ªùng th√¨']

		# Check high-risk violations
		for phrase in high_risk_phrases:
			if phrase in response_lower:
				analysis['violations'].append({'phrase': phrase, 'severity': 'high', 'score_reduction': 0.5})
				analysis['overall_score'] -= 0.5

		# Check medium-risk warnings
		for phrase in medium_risk_phrases:
			if phrase in response_lower:
				analysis['warnings'].append({'phrase': phrase, 'severity': 'medium', 'score_reduction': 0.2})
				analysis['overall_score'] -= 0.2

		# Check low-risk notices
		for phrase in low_risk_phrases:
			if phrase in response_lower:
				analysis['warnings'].append({'phrase': phrase, 'severity': 'low', 'score_reduction': 0.1})
				analysis['overall_score'] -= 0.1

		# Ensure score doesn't go below 0
		analysis['overall_score'] = max(0.0, analysis['overall_score'])

		# Determine compliance level
		if analysis['overall_score'] >= 0.9:
			analysis['compliance_level'] = 'full'
		elif analysis['overall_score'] >= 0.7:
			analysis['compliance_level'] = 'good'
		elif analysis['overall_score'] >= 0.5:
			analysis['compliance_level'] = 'acceptable'
		else:
			analysis['compliance_level'] = 'poor'

		# Generate recommendations
		if analysis['violations']:
			analysis['recommendations'].append('Lo·∫°i b·ªè c√°c c·ª•m t·ª´ ƒë·∫£m b·∫£o l·ª£i nhu·∫≠n')
		if analysis['warnings']:
			analysis['recommendations'].append('C√¢n nh·∫Øc ƒëi·ªÅu ch·ªânh ng√¥n t·ª´ ƒë·ªÉ gi·∫£m t√≠nh khuy·∫øn kh√≠ch ƒë·∫ßu t∆∞')
		if analysis['overall_score'] < 0.8:
			analysis['recommendations'].append('Th√™m c·∫£nh b√°o r·ªßi ro v√† khuy·∫øn ngh·ªã tham kh·∫£o chuy√™n gia')

		analysis_time = time.time() - start_time
		color_logger.performance_metric('safety_analysis_time', f'{analysis_time:.3f}', 's')

		color_logger.success(
			'Safety analysis completed',
			overall_score=analysis['overall_score'],
			compliance_level=analysis['compliance_level'],
			violations_count=len(analysis['violations']),
			warnings_count=len(analysis['warnings']),
			analysis_time=analysis_time,
		)

		return analysis

	@staticmethod
	def get_compliance_report() -> Dict[str, Any]:
		"""Get compliance guidelines and statistics"""
		start_time = time.time()
		color_logger.info(
			f'üìã {Colors.BOLD}COMPLIANCE_REPORT:{Colors.RESET}{Colors.BRIGHT_WHITE} Generating compliance report',
			Colors.BRIGHT_WHITE,
		)

		report = {
			'guidelines_count': len(ValidationPrompts.SAFETY_GUIDELINES.split('\n')),
			'prohibited_phrases': [
				'ƒë·∫£m b·∫£o l·ª£i nhu·∫≠n',
				'ch·∫Øc ch·∫Øn sinh l·ªùi',
				'kh√¥ng c√≥ r·ªßi ro',
				'khuy·∫øn ngh·ªã mua',
				'n√™n b√°n ngay',
				'100% an to√†n',
			],
			'required_disclosures': [
				'C·∫£nh b√°o r·ªßi ro ƒë·∫ßu t∆∞',
				'Khuy·∫øn ngh·ªã tham kh·∫£o chuy√™n gia',
				'Tu√¢n th·ªß quy ƒë·ªãnh ph√°p lu·∫≠t Vi·ªát Nam',
			],
			'compliance_standards': {
				'financial_advice': 'Kh√¥ng ƒë∆∞a ra khuy·∫øn ngh·ªã ƒë·∫ßu t∆∞ c·ª• th·ªÉ',
				'risk_disclosure': 'Lu√¥n c·∫£nh b√°o v·ªÅ r·ªßi ro',
				'legal_compliance': 'Tu√¢n th·ªß quy ƒë·ªãnh NHNN v√† SBV',
			},
		}

		report_time = time.time() - start_time
		color_logger.performance_metric('compliance_report_time', f'{report_time:.3f}', 's')

		color_logger.success(
			'Compliance report generated',
			guidelines_lines=report['guidelines_count'],
			prohibited_phrases=len(report['prohibited_phrases']),
			required_disclosures=len(report['required_disclosures']),
			report_time=report_time,
		)

		return report


# Module initialization complete
color_logger.success(
	'CGSEM Prompts module initialized successfully',
	classes_loaded=['SystemPrompts', 'PromptTemplates', 'ValidationPrompts'],
	prompt_types=['default', 'media', 'event', 'tech'],
	validation_enabled=True,
	cgsem_optimized=True,
)

color_logger.info(
	f'‚úÖ {Colors.BOLD}CGSEM MODULE_READY:{Colors.RESET}{Colors.BRIGHT_GREEN} CGSEM prompts configuration module ready for use',
	Colors.BRIGHT_GREEN,
	total_classes=3,
	safety_validation=True,
	rag_enhancement=True,
	cgsem_context=True,
)
