import json
import re
from typing import Dict

from .agent_schema import MeetingState
import tiktoken


from app.core.config import (
	CONTEXT_PRICE_PER_MILLION,
	INPUT_PRICE_PER_MILLION,
	OUTPUT_PRICE_PER_MILLION,
)


def calculate_price(input_tokens: int, output_tokens: int, context_tokens: int = 0) -> float:
	"""Calculate total price based on token usage.

	Args:
	    input_tokens (int): Number of input tokens
	    output_tokens (int): Number of output tokens
	    context_tokens (int): Number of context tokens

	Returns:
	    float: Total price in USD
	"""
	input_price = (input_tokens / 1_000_000) * INPUT_PRICE_PER_MILLION
	output_price = (output_tokens / 1_000_000) * OUTPUT_PRICE_PER_MILLION
	context_price = (context_tokens / 1_000_000) * CONTEXT_PRICE_PER_MILLION
	return input_price + output_price + context_price


def parse_json_from_response(response: str) -> Dict:
	"""_summary_

	Args:
	    response (str): _description_

	Returns:
	    Dict: _description_
	"""

	try:
		parsed_response = json.loads(response)
	except json.JSONDecodeError:
		try:
			new_response = response.split('```')[1][5:]
			parsed_response = json.loads(new_response)
		except json.JSONDecodeError:
			pattern = r'(json)\s*({.*})'
			match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)

			if match:
				parsed_response = json.loads(match.group(2))
			else:
				parsed_response = {}
	return parsed_response


def count_tokens(text: str, model: str = 'gpt-4') -> int:
	"""Count the number of tokens in a text string.

	Args:
	    text (str): The text to count tokens for
	    model (str): The model to use for counting tokens

	Returns:
	    int: Number of tokens
	"""
	if not text:
		return 0

	# Handle Gemini models
	if 'gemini' in model.lower():
		# Gemini approximates tokens as ~4 characters per token
		return len(text) // 4

	# Handle Google/Vertex AI models through LiteLLM
	elif model.lower().startswith(('google/', 'vertex_ai/')):
		# Use same approximation for Google models
		return len(text) // 4

	# Handle OpenAI models with tiktoken
	else:
		try:
			encoding = tiktoken.encoding_for_model(model)
			return len(encoding.encode(text))
		except (KeyError, ValueError, ImportError):
			# Fallback for unknown models
			# Average English text is ~4 chars per token
			return len(text) // 4


def generate_meeting_note(meeting_state: MeetingState) -> str:
	"""Generate a Markdown formatted meeting note from the provided meeting state.

	Args:
	    meeting_state (MeetingState): Processed meeting data containing:
	        - chunk_summaries: List of ChunkSummary objects.
	        - meeting_items: List of MeetingItems objects (each with decisions, action_items, and questions).

	Returns:
	    str: Markdown formatted meeting note.
	"""
	result = []

	result.append('# ğŸ“‹ BiÃªn báº£n cuá»™c há»p\n')

	chunk_summaries = meeting_state.get('chunk_summaries', [])

	best_chunk = None
	max_info_count = -1

	for chunk in chunk_summaries:
		if not hasattr(chunk, 'summary') or not chunk.summary or chunk.summary == 'KhÃ´ng Ä‘á»§ thÃ´ng tin cÃ³ Ã½ nghÄ©a Ä‘á»ƒ tÃ³m táº¯t':
			continue

		info_count = (
			len(getattr(chunk, 'key_points', []))
			+ len(getattr(chunk, 'facts', []))
			+ len(getattr(chunk, 'problems', []))
			+ len(getattr(chunk, 'solutions', []))
			+ len(getattr(chunk, 'risks', []))
			+ len(getattr(chunk, 'next_steps', []))
		)

		if info_count > max_info_count:
			max_info_count = info_count
			best_chunk = chunk

	if best_chunk is None and chunk_summaries:
		best_chunk = chunk_summaries[0]

	all_key_points = []
	all_facts = []
	all_problems = []
	all_solutions = []
	all_risks = []
	all_next_steps = []

	for chunk in chunk_summaries:
		all_key_points.extend(getattr(chunk, 'key_points', []))
		all_facts.extend(getattr(chunk, 'facts', []))
		all_problems.extend(getattr(chunk, 'problems', []))
		all_solutions.extend(getattr(chunk, 'solutions', []))
		all_risks.extend(getattr(chunk, 'risks', []))
		all_next_steps.extend(getattr(chunk, 'next_steps', []))

	all_key_points = list(dict.fromkeys(all_key_points))
	all_facts = list(dict.fromkeys(all_facts))
	all_problems = list(dict.fromkeys(all_problems))
	all_solutions = list(dict.fromkeys(all_solutions))
	all_risks = list(dict.fromkeys(all_risks))
	all_next_steps = list(dict.fromkeys(all_next_steps))

	if best_chunk and hasattr(best_chunk, 'agenda') and best_chunk.agenda and best_chunk.agenda != 'KhÃ´ng Ä‘á»§ thÃ´ng tin Ä‘á»ƒ xÃ¡c Ä‘á»‹nh chÆ°Æ¡ng trÃ¬nh nghá»‹ sá»±':
		result.append('## ğŸ§­ ChÆ°Æ¡ng trÃ¬nh nghá»‹ sá»±')
		result.append(f'- {best_chunk.agenda}\n')

	if best_chunk and hasattr(best_chunk, 'summary') and best_chunk.summary and best_chunk.summary != 'KhÃ´ng Ä‘á»§ thÃ´ng tin cÃ³ Ã½ nghÄ©a Ä‘á»ƒ tÃ³m táº¯t':
		result.append('## ğŸ“ TÃ³m táº¯t')
		result.append(f'{best_chunk.summary}\n')

	def add_bullet_section(title: str, items: list):
		if items:
			result.append(f'## {title}')
			for item in items:
				result.append(f'- {item}')
			result.append('')

	add_bullet_section('ğŸ”‘ Äiá»ƒm chÃ­nh', all_key_points)
	add_bullet_section('ğŸ“Œ ThÃ´ng tin quan trá»ng', all_facts)
	add_bullet_section('âš ï¸ Váº¥n Ä‘á»', all_problems)
	add_bullet_section('ğŸ’¡ Giáº£i phÃ¡p', all_solutions)
	add_bullet_section('ğŸš§ Rá»§i ro', all_risks)
	add_bullet_section('ğŸ“ BÆ°á»›c tiáº¿p theo', all_next_steps)

	decisions = []
	action_items = []
	questions = []

	for item in meeting_state.get('meeting_items', []):
		if hasattr(item, 'decisions') and item.decisions:
			decisions.extend(item.decisions)
		if hasattr(item, 'action_items') and item.action_items:
			action_items.extend(item.action_items)
		if hasattr(item, 'questions') and item.questions:
			questions.extend(item.questions)

	if decisions:
		result.append('## âœ… Quyáº¿t Ä‘á»‹nh')
		for idx, d in enumerate(decisions, 1):
			topics = ' / '.join(d.topic) if d.topic else f'Quyáº¿t Ä‘á»‹nh {idx}'
			result.append(f'### {idx}. {topics}')
			result.append(f'- **Ná»™i dung quyáº¿t Ä‘á»‹nh**: {d.decision}')
			if d.impact:
				result.append(f'- **TÃ¡c Ä‘á»™ng**: {d.impact}')
			if d.timeline:
				result.append(f'- **Thá»i gian**: {d.timeline}')
			if d.stakeholders:
				result.append(f'- **NgÆ°á»i liÃªn quan**: {", ".join(d.stakeholders)}')
			if d.next_steps:
				result.append(f'- **BÆ°á»›c tiáº¿p theo**: ' + '; '.join(d.next_steps))
			result.append('')

	if action_items:
		result.append('## ğŸ“Œ Nhiá»‡m vá»¥')
		for idx, a in enumerate(action_items, 1):
			topics = ', '.join(a.topic) if a.topic else f'Nhiá»‡m vá»¥ {idx}'
			result.append(f'### {idx}. {topics}')
			result.append(f'- **NgÆ°á»i thá»±c hiá»‡n**: {a.assignee}')
			result.append(f'- **Nhiá»‡m vá»¥**: {a.task}')
			if a.deadline:
				result.append(f'- **Háº¡n chÃ³t**: {a.deadline}')
			result.append('')

	if questions:
		result.append('## â“ CÃ¢u há»i')
		for idx, q in enumerate(questions, 1):
			result.append(f'### {idx}. {q.question}')
			if q.asker:
				result.append(f'- **NgÆ°á»i há»i**: {q.asker}')
			result.append(f'- **ÄÃ£ tráº£ lá»i**: {"âœ… CÃ³" if q.answered else "âŒ ChÆ°a"}')
			if q.answer:
				result.append(f'- **CÃ¢u tráº£ lá»i**: {q.answer}')
			if q.topic:
				result.append(f'- **Chá»§ Ä‘á»**: {", ".join(q.topic)}')
			result.append('')

	if len(result) <= 2:  # Chá»‰ cÃ³ tiÃªu Ä‘á» vÃ  xuá»‘ng dÃ²ng
		result.append('## â„¹ï¸ ThÃ´ng bÃ¡o')
		result.append('KhÃ´ng tÃ¬m tháº¥y Ä‘á»§ thÃ´ng tin cÃ³ Ã½ nghÄ©a Ä‘á»ƒ táº¡o ghi chÃº cuá»™c há»p chi tiáº¿t.')
		result.append('Vui lÃ²ng cung cáº¥p transcript hoÃ n chá»‰nh hÆ¡n Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t hÆ¡n.')

	return '\n'.join(result)


class TokenTracker:
	def __init__(self):
		self.input_tokens = 0
		self.output_tokens = 0
		self.context_tokens = 0

	@property
	def total_tokens(self):
		return self.input_tokens + self.output_tokens + self.context_tokens

	def add_input_tokens(self, tokens: int):
		self.input_tokens += tokens

	def add_output_tokens(self, tokens: int):
		self.output_tokens += tokens

	def add_context_tokens(self, tokens: int):
		self.context_tokens += tokens
