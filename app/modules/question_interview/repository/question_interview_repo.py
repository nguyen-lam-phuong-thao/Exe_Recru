"""
Question composer repository layer.
"""

import logging
import uuid
from typing import List, Optional, Dict, Any
from langgraph.checkpoint.memory import MemorySaver

from app.exceptions.exception import NotFoundException, ValidationException, CustomHTTPException
from app.middleware.translation_manager import _

from ..workflows.question_generation import QuestionGenerationWorkflow
from ..workflows.question_generation.config.workflow_config import QuestionGenerationWorkflowConfig
from ..schemas.interview_request import UploadCVInterviewStartRequest, AnalyzeUserProfileRequest
from ..schemas.interview_response import QuestionGenerationResponse, UserProfileAnalysisResponse
from ..schemas.interview_schemas import UserProfile, Question, SubmitInterviewAnswerRequest


logger = logging.getLogger(__name__)


class InterviewComposerRepo:
	"""
	Repository layer for question composer module.

	Handles business logic for question generation and user profile analysis.
	"""

	def __init__(self):
		logger.info('Initializing InterviewComposerRepo (in-memory)')
		self.memory = MemorySaver()
		self.config = QuestionGenerationWorkflowConfig.from_env()
		self.workflow = QuestionGenerationWorkflow(self.config)
		self.compiled_workflow = self.workflow.workflow.compile(checkpointer=self.memory)
		logger.info('InterviewComposerRepo initialized (in-memory)')

	def _safe_questions_list(self, raw_list):
		safe_list = []
		for q in (raw_list or []):
			if isinstance(q, Question):
				safe_list.append(q)
			elif isinstance(q, dict):
				try:
					safe_list.append(Question(**q))
				except Exception as e:
					logger.warning(f"Invalid previous_question dict: {q} ({e})")
			else:
				logger.warning(f"Skipping invalid previous_question (not dict or Question): {q}")
		return safe_list

	async def generate_questions(self, request: UploadCVInterviewStartRequest) -> QuestionGenerationResponse:
		"""
		Generate intelligent questions based on user-provided focus areas. All other fields are generated by the backend.
		"""
		print('Starting question generation process (in-memory)')
		session_id = str(uuid.uuid4())
		print(f'Generated session_id: {session_id}')
		config = {"configurable": {"thread_id": session_id}}

		# The input to the workflow should contain the initial values for the graph's state.
		# The checkpointer will manage loading and saving the state across invocations.
		workflow_input = {
			'user_profile': UserProfile(),  # Empty/default profile
			'generated_questions': [],
			'all_previous_questions': [],
			'current_iteration': 0,
			'max_iterations': 5,
			'analysis_decision': None,
			'completeness_score': 0.0,
			'missing_areas': [],
			'focus_areas': request.focus_areas,
			'should_continue': True,
			'workflow_complete': False,
			'error_message': None,
			'generation_history': [],
			'total_questions_generated': 0,
			'session_id': session_id,
		}

		# Run the workflow. `ainvoke` with a checkpointer handles state automatically.
		result = await self.compiled_workflow.ainvoke(workflow_input, config=config)

		# Build response from the final state of the workflow
		return QuestionGenerationResponse(
			session_id=session_id,
			questions=result.get('generated_questions', []),
			analysis=str(result.get('analysis_decision', '')),
			next_focus_areas=result.get('focus_areas', []),
			completeness_score=result.get('completeness_score', 0.0),
			should_continue=result.get('should_continue', True),
			current_iteration=result.get('current_iteration', 0),
			total_questions_generated=result.get('total_questions_generated', 0),
		)

	async def generate_question_from_cv_text(
		self,
		cleaned_cv_text: str,
		job_description: str,
		previous_questions: list,
		session_id: str,
	) -> QuestionGenerationResponse:
		# No session state is stored; all context is provided by BE
		config = {"configurable": {"thread_id": session_id}}
		initial_state = {
			'user_profile': UserProfile(),
			'generated_questions': [],
			'all_previous_questions': previous_questions,
			'current_iteration': 0,
			'max_iterations': 5,
			'analysis_decision': None,
			'completeness_score': 0.0,
			'missing_areas': [],
			'focus_areas': [],
			'should_continue': True,
			'workflow_complete': False,
			'error_message': None,
			'generation_history': [],
			'total_questions_generated': 0,
			'session_id': session_id,
			'cv_text': cleaned_cv_text,
			'job_description': job_description,
		}
		result = await self.compiled_workflow.ainvoke(initial_state, config=config)
		return QuestionGenerationResponse(
			session_id=session_id,
			questions=result.get('generated_questions', []),
			analysis=str(result.get('analysis_decision', '')),
			next_focus_areas=result.get('focus_areas', []),
			completeness_score=result.get('completeness_score', 0.0),
			should_continue=result.get('should_continue', True),
			current_iteration=result.get('current_iteration', 0),
			total_questions_generated=result.get('total_questions_generated', 0),
		)

	async def evaluate_answer_and_continue(
		self,
		cleaned_cv_text: str,
		job_description: str,
		previous_questions: list,
		answer_text: str,
		session_id: str,
	) -> Dict[str, Any]:
		# Attach the answer to the last unanswered question in previous_questions
		state = {
			'user_profile': UserProfile(),
			'generated_questions': [],
			'all_previous_questions': previous_questions,
			'current_iteration': len(previous_questions),
			'max_iterations': 5,
			'analysis_decision': None,
			'completeness_score': 0.0,
			'missing_areas': [],
			'focus_areas': [],
			'should_continue': True,
			'workflow_complete': False,
			'error_message': None,
			'generation_history': [],
			'total_questions_generated': len(previous_questions),
			'session_id': session_id,
			'cv_text': cleaned_cv_text,
			'job_description': job_description,
		}
		# The answer should already be attached in previous_questions by BE
		final_state = await self.compiled_workflow.ainvoke(state, config={"configurable": {"thread_id": session_id}})
		all_answered = all(
			(q.answer if hasattr(q, "answer") else q.get("answer"))
			for q in final_state.get("all_previous_questions", [])
		)
		if all_answered:
			final_feedback = {
				"score": final_state.get("completeness_score", 0.0),
				"feedback": "Bạn đã hoàn thành phỏng vấn. Dưới đây là nhận xét tổng quát về hồ sơ của bạn.",
				"summary": getattr(final_state.get('analysis_decision', None), 'reasoning', ''),
				"all_answers": [
					{
						"question": q.Question if hasattr(q, "Question") else q.get("Question", ""),
						"answer": getattr(q, "answer", "") if hasattr(q, "answer") else q.get("answer", "")
					}
					for q in final_state.get("all_previous_questions", [])
				]
			}
			return {
				"feedback": final_feedback,
				"next_question": None,
				"current_iteration": final_state.get("current_iteration", 0),
				"completeness_score": final_state.get("completeness_score", 0.0),
				"should_continue": False,
			}
		# Otherwise, return next question
		next_question = None
		for q in reversed(final_state.get('all_previous_questions', [])):
			if hasattr(q, "answer") and not getattr(q, "answer", None):
				next_question = q
				break
			elif isinstance(q, dict) and not q.get('answer'):
				next_question = q
				break
		feedback = {
			'score': 0.9,
			'feedback': 'Câu trả lời tốt. Bạn có thể cụ thể hóa thêm ví dụ.',
			'suggestions': 'Hãy liên hệ trải nghiệm với vai trò AI Engineer.'
		}
		return {
			"feedback": feedback,
			"next_question": next_question,
			"current_iteration": final_state.get('current_iteration', 0),
			"completeness_score": final_state.get('completeness_score', 0.0),
			"should_continue": final_state.get('should_continue', False),
		}

	async def analyze_user_profile(self, request: AnalyzeUserProfileRequest) -> UserProfileAnalysisResponse:
		"""
		Analyze user profile completeness without generating new questions.
		"""
		print('Starting user profile analysis')
		print(f'Analysis request - User profile provided: {bool(request.user_profile)}')

		try:
			# Validate request
			print('Validating analysis request')
			if not request.user_profile:
				logger.warning('User profile is required but not provided')
				raise ValidationException(_('user_profile_required'))

			print('Request validation passed')

			# Prepare user profile
			print('Preparing user profile for analysis')
			print(f'User profile data keys: {list(request.user_profile.keys())}')
			user_profile = UserProfile(**request.user_profile)
			print('User profile object created successfully')

			# For analysis, previous_questions is always [] (or could fetch from session if needed)
			previous_questions = []

			# Use workflow for analysis
			temp_state = {
				'user_profile': user_profile,
				# 'cv_data': {},
				'generated_questions': [],
				'all_previous_questions': previous_questions,
				'current_iteration': 0,
				'max_iterations': 1,
				'analysis_decision': None,
				'completeness_score': 0.0,
				'missing_areas': [],
				'focus_areas': [],
				'should_continue': True,
				'workflow_complete': False,
				'error_message': None,
				'generation_history': [],
				'total_questions_generated': 0,
				'session_id': str(uuid.uuid4()),
			}
			result = await self.compiled_workflow.ainvoke(temp_state)

			logger.info('Profile analysis completed successfully')
			logger.info(f'Analysis results summary:')
			logger.info(f'Completeness score: {result.get("completeness_score", 0.0):.3f}')
			logger.info(f'Missing areas count: {len(result.get("missing_areas", []))}')
			logger.info(f'Analysis length: {len(result.get("analysis_decision", ""))} characters')
			logger.info(f'Should continue: {result.get("should_continue", True)}')

			missing_areas = result.get('missing_areas', [])
			if missing_areas:
				logger.info(f'Missing areas: {missing_areas}')
			else:
				logger.info('No missing areas identified')

			response = UserProfileAnalysisResponse(
				completeness_score=result.get('completeness_score', 0.0),
				missing_areas=missing_areas,
				analysis=str(result.get('analysis_decision', '')),
				should_continue=result.get('should_continue', True),
			)

			logger.info(f'User profile analysis completed successfully!')
			logger.info(f'Final analysis score: {response.completeness_score:.3f}')

			return response

		except ValidationException as e:
			logger.error(f'Validation error in profile analysis: {str(e)}')
			raise
		except Exception as e:
			logger.error(f'Unexpected error in profile analysis: {str(e)}', exc_info=True)
			raise CustomHTTPException(message=_('profile_analysis_failed'))

	async def get_question_session(self, session_id: str) -> Dict[str, Any]:
		"""
		Get question session by ID.
		"""
		logger.info(f'Retrieving question session: {session_id}')

		config = {"configurable": {"thread_id": session_id}}
		state = await self.memory.aget(config)
		if not state:
			logger.warning(f'Session not found: {session_id}')
			raise NotFoundException(_('session_not_found'))

		logger.info(f'Session found - ID: {session_id}, Status: {state.get("status", "N/A")}, Iteration: {state.get("current_iteration", "N/A")}/{state.get("max_iterations", "N/A")}')
		logger.info(f'Session stats - Questions generated: {state.get("total_questions_generated", 0)}, Completeness: {state.get("completeness_score", 0.0):.3f}')

		return state

	async def search_question_sessions(self) -> List[Dict[str, Any]]:
		"""
		Search question sessions with filtering.
		"""
		logger.info('Starting question sessions search')
		logger.info('MemorySaver does not support listing all sessions by default; you may need to extend it if needed')
		return []

	def get_service_info(self) -> Dict[str, Any]:
		"""Get repository and workflow information"""
		logger.info('Retrieving service information')

		try:
			workflow_info = self.workflow.get_workflow_info()
			config_dict = self.config.to_dict()

			service_info = {'name': 'Question Composer Repository', 'version': '1.0.0', 'workflow_info': workflow_info, 'config': config_dict, 'features': ['Intelligent question generation', 'User profile analysis', 'Session management', 'Adaptive questioning based on completeness', '4 question types support', 'Vietnamese language optimized', 'LangGraph workflow integration', 'Database persistence']}

			logger.info('Service information retrieved successfully')
			logger.info(f'Config keys: {list(config_dict.keys())}')
			logger.info(f'Workflow info keys: {list(workflow_info.keys())}')

			return service_info

		except Exception as e:
			logger.error(f'Error retrieving service info: {str(e)}', exc_info=True)
			return {'name': 'Question Composer Repository', 'version': '1.0.0', 'error': f'Failed to retrieve full info: {str(e)}'}
